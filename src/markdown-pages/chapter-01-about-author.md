---
title: "Chapter 1: About the Author & Why This Book"
slug: "/ai-book-master/chapter-01-about-author"
date: "2024-01-02"
order: 1
---

## About the author

### Education

I took a practical route into AI and management: a Bachelor’s in Applied Mathematics and Economics (2010–2014), followed by a Master’s in Industrial Engineering and Management (2014–2016), and then a PhD in Social Sciences (Management & Administration) completed at Kaunas University of Technology (2016–2020). 

### Academic work

Today I serve as an Associate Professor (docentas) at Vilnius University’s Faculty of Mathematics and Informatics, where I teach Deep Learning and Ethical AI for Social Good. Since 2024, I’ve also been a Senior Researcher at the same faculty, focusing on deep learning, remote sensing, and AI ethics. Earlier, at Kaunas University of Technology (2016–2022), I taught logistics and analytics, coordinated the “Big Business Data Analytics” master’s program, and helped launch “Elements of AI.” Over the years I’ve supervised more than 70 bachelor’s and 9 master’s theses. 
 
### Scientific projects

My research portfolio spans EU and national initiatives. I lead the Research Council of Lithuania project “AI-Driven Multimodal Remote Sensing Analysis” (2025–2027) and contribute to two European Space Agency projects: “Real-Time Mapping of Peat Hydration Using Data Fusion & Deep Learning” (2025–2026) and “Urban Climate” (2024–2026). I also co-led a pilot at Vilnius University on prompt engineering for social-work applications (2024–2025). Previous work includes a postdoctoral project on sustainable e-grocery routing (2022–2024), a national climate-monitoring project on multi-objective satellite image recognition (2023–2026), and applied R&D such as a MITA-funded real-estate valuation expert system (2022) and a GovTech pilot on real-time satellite imagery for Lithuania (2020).  

### Business experience

Alongside academia, I run AI Conformity & Research Consulting, MB (since 2024), where I help organizations with AI conformity assessment, ISO standards (including ISO/IEC 42001), and R&D road-mapping. Before that, I led Market Trend Valuation Center (2020–2023), focused on AI-driven asset valuation and training, worked as a data scientist at Value Advise (2021–2022) on a MITA Inostart project, and earlier consulted as a freelance analyst—including economic forecasting and automation for Euromonitor International. I started to help companies create AI solutions, where I join them as a strategic consultant, sometimes as investor notable projects: diet specialist based on LLM, chatbot for social services, remote sensing for carbon footpring monitoring and others.

### Training & speaking

I work with managers and teams across finance, legal, public sector, logistics, and tech, turning AI from buzzwords into workflows. My sessions range from executive briefings on strategy and risk to hands-on workshops in LLM use, prompt design, and AI project scoping. I usually leave teams with a simple checklist, a first-30-days plan, and a view of how ISO/IEC 42001 and EU AI Act requirements translate into day-to-day practice. I also speak at conferences and industry forums on AI regulation, standards, and practical adoption—often bridging business goals with governance. Recent appearances have covered AI Act readiness, data and model risk, and sector-specific use cases, with a consistent focus on clear decision frames, measurable ROI, and ethical deployment that scales.
 
### Work groups related to AI regulation

My policy and standards work centers on making AI safer and more accountable in practice. I contribute to Lithuania’s Advisory Working Group for Horizon Europe Action Group 4 (“Digital Technologies, Industry, Space”) and serve on the national standardization committee LST TK 4 (“Information Technology”). I coordinate the Conformity Assessment work group at Lithuania’s AI Governance Forum, have advised the Innovation Agency on AI Act implementation, and joined the European Commission’s AI Board as part of the Standards LT delegation. I also participate as an expert in CEN/CLC/JTC 21/WG3 on datasets and bias management. 
 

## Why I wrote this book

I didn’t start out as a “math person.” At university, theory felt far from real life—until I joined a startup building computer vision systems for manufacturers. Suddenly, the equations had edges: they detected defects, counted items, saved time. The company didn’t make it, and I went through more than ten roles trying to find a place where applied math and real-world problems met. Startups weren’t yet “a thing” in my environment, so I turned to the closest place where curiosity and practice could coexist: academia.

Along the way, I freelanced in data analytics and kept leveling up through open communities and online courses. I took hundreds of them. The fast.ai courses by Jeremy Howard were a turning point: first machine learning, then deep learning—the kind of practical, no-nonsense teaching that lets you build things that work. Over the last decade, I’ve stayed close to that spirit: solve real problems, share what you learn. In my early carrer days I also joined and I am still active in a enterpreneruship development system, Yager group, which helped me get leadership, comunicatination, finance skills.

So why write this now? Because we’ve entered the intelligence age. With large language models (LLMs) and their smaller cousins (SLMs), you can multiply your productivity and creativity—if you know how to use them. Too often, AI gets framed as a mysterious black box or a looming superintelligence, which creates fear and inaction. I prefer a different story: accessible tools, clear principles, and hands-on habits that any motivated person or team can adopt.

My view is simple: opportunity should be widely available, and what you build depends on your own effort and discipline. This book distills what I’ve learned working with data, machine learning, and AI for more than ten years—so you can improve your daily work, launch smarter projects, and maybe create ideas nobody has tried before. If some technical details are simplified, that’s by design. I’ll focus on durable principles and decision frames, and I’ll point you to practical resources if you want to go deeper.

## Who this book is for

This book is for people who want results, not hype:

Managers and business professionals who need plain-language explanations, practical use cases, and simple ways to measure ROI. You’ll find checklists, decision trees, and examples you can copy into your workflow the same day.

Entrepreneurs and small/medium businesses who want to apply AI without giant budgets. We’ll focus on lightweight tools, repeatable processes, and how to scale responsibly.

Public-sector leaders and policy professionals who must balance innovation with accountability. I’ll translate technical risks into governance actions and—when we get to that chapter—connect them to EU AI Act obligations in practical terms.

Technical readers are welcome, with one note: this isn’t a coding manual. You’ll find principles, patterns, and safeguards you can align with your engineering practice, plus links to deeper technical material if you want to build.

What this book is not: it’s not doom, not hype, and not a catalog of buzzwords. It’s a field guide to using AI responsibly to do better work—clear enough for non-technical readers, concrete enough for teams that need to ship, and aligned with the governance that’s arriving fast.

## How to Use This Book

This book is written in plain Markdown inside Jupyter notebooks and drafted with the [Solveit](https://solveit.fast.ai/) workflow by Jeremy Howard, so everything stays lightweight, searchable, and easy to remix. Read it straight through or jump to the chapters most relevant to your role—each section stands alone with clear takeaways.

Prefer to listen? There’s an accompanying podcast version generated with NotebookLM so you can absorb the material on the go.

The entire manuscript lives on GitHub in Markdown and is open source: you’re free to reuse, adapt, and even load chapters into your favorite LLM for richer, project-specific context. Markdown makes ingestion clean and reliable; for best practices on preparing docs for LLMs, see the emerging “llm.txt” standard: [https://www.answer.ai/posts/2024-09-03-llmstxt.html](https://www.answer.ai/posts/2024-09-03-llmstxt.html). For more on publishing clean, LLM-friendly docs from notebooks, check out [nbdev](https://nbdev.fast.ai/)—in short: check the details in **llm.txt** or **nbdev**.
